{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPxR2+iFb+ZPP6RFOROfwyw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshc1004/Task1/blob/main/Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q11iFE31n9g7",
        "outputId": "2fe7e75a-af40-4b1b-8e47-97d5b6a7dd1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting coach 1\n",
            "Ended coach 1 with 339 frames\n",
            "Starting coach 2\n",
            "Ended coach 2 with 92 frames\n",
            "Starting coach 3\n",
            "Ended coach 3 with 56 frames\n",
            "Starting coach 4\n",
            "Ended coach 4 with 54 frames\n",
            "Starting coach 5\n",
            "Ended coach 5 with 50 frames\n",
            "Starting coach 6\n",
            "Ended coach 6 with 53 frames\n",
            "Starting coach 7\n",
            "Ended coach 7 with 52 frames\n",
            "Starting coach 8\n",
            "Ended coach 8 with 66 frames\n",
            "Starting coach 9\n",
            "Ended coach 9 with 52 frames\n",
            "Starting coach 10\n",
            "Ended coach 10 with 58 frames\n",
            "Starting coach 11\n",
            "Ended coach 11 with 50 frames\n",
            "Starting coach 12\n",
            "Ended coach 12 with 53 frames\n",
            "Starting coach 13\n",
            "Ended coach 13 with 51 frames\n",
            "Starting coach 14\n",
            "Ended coach 14 with 59 frames\n",
            "Starting coach 15\n",
            "Ended coach 15 with 50 frames\n",
            "Starting coach 16\n",
            "Ended coach 16 with 58 frames\n",
            "Starting coach 17\n",
            "Ended coach 17 with 50 frames\n",
            "Starting coach 18\n",
            "Ended coach 18 with 61 frames\n",
            "Starting coach 19\n",
            "Ended coach 19 with 51 frames\n",
            "Starting coach 20\n",
            "Ended coach 20 with 50 frames\n",
            "Starting coach 21\n",
            "Ended coach 21 with 55 frames\n",
            "Starting coach 22\n",
            "Total coaches detected: 22\n",
            "Report generated at: processed_output/12309_report.pdf\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from fpdf import FPDF\n",
        "\n",
        "def main(video_path, output_dir, train_number='12309'):\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load video\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error opening video file\")\n",
        "        return\n",
        "\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "\n",
        "    # Background subtractor with adjusted parameters\n",
        "    subtractor = cv2.createBackgroundSubtractorMOG2(history=200, varThreshold=30, detectShadows=True)\n",
        "\n",
        "    coach_count = 0\n",
        "    in_coach = False\n",
        "    frame_count = 0\n",
        "    coach_frames = []\n",
        "    writer = None\n",
        "    selected_images = []\n",
        "\n",
        "    # Tunable parameters (adjust based on video)\n",
        "    gap_threshold = 0.1  # Increased for potentially noisier backgrounds\n",
        "    min_coach_frames = 50  # Increased to ensure valid coach length\n",
        "    strip_width = width // 10  # Wider strip for better gap detection\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        # Apply background subtraction\n",
        "        fgmask = subtractor.apply(frame)\n",
        "\n",
        "        # Preprocess mask to reduce noise\n",
        "        fgmask = cv2.medianBlur(fgmask, 5)\n",
        "        _, fgmask = cv2.threshold(fgmask, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # Check for gap: Analyze a central vertical strip\n",
        "        strip_start = width // 2 - strip_width // 2\n",
        "        strip_end = width // 2 + strip_width // 2\n",
        "        strip_mask = fgmask[:, strip_start:strip_end]\n",
        "        foreground_ratio = np.mean(strip_mask > 0)\n",
        "\n",
        "        if foreground_ratio > gap_threshold:\n",
        "            if not in_coach:\n",
        "                in_coach = True\n",
        "                coach_count += 1\n",
        "                coach_dir = os.path.join(output_dir, f\"{train_number}_{coach_count}\")\n",
        "                os.makedirs(coach_dir, exist_ok=True)\n",
        "                video_path_out = os.path.join(coach_dir, f\"{train_number}_{coach_count}.mp4\")\n",
        "                writer = cv2.VideoWriter(video_path_out, fourcc, fps, (width, height))\n",
        "                coach_frames = []\n",
        "                print(f\"Starting coach {coach_count}\")\n",
        "\n",
        "            writer.write(frame)\n",
        "            coach_frames.append(frame)\n",
        "        else:\n",
        "            if in_coach and len(coach_frames) >= min_coach_frames:\n",
        "                in_coach = False\n",
        "                writer.release()\n",
        "                print(f\"Ended coach {coach_count} with {len(coach_frames)} frames\")\n",
        "\n",
        "                # Extract frames (every 10th)\n",
        "                for i, coach_frame in enumerate(coach_frames[::10]):\n",
        "                    frame_path = os.path.join(coach_dir, f\"{train_number}_{coach_count}_{i+1}.jpg\")\n",
        "                    cv2.imwrite(frame_path, coach_frame)\n",
        "\n",
        "                # Select middle frame\n",
        "                mid_frame = coach_frames[len(coach_frames)//2]\n",
        "                mid_frame_path = os.path.join(coach_dir, f\"{train_number}_{coach_count}_mid.jpg\")\n",
        "                cv2.imwrite(mid_frame_path, mid_frame)\n",
        "\n",
        "                # Detect components\n",
        "                annotated_path = detect_components(mid_frame_path, coach_dir, train_number, coach_count)\n",
        "                selected_images.append(annotated_path)\n",
        "\n",
        "    cap.release()\n",
        "    if writer:\n",
        "        writer.release()\n",
        "\n",
        "    print(f\"Total coaches detected: {coach_count}\")\n",
        "    generate_report(selected_images, output_dir, train_number, coach_count)\n",
        "\n",
        "def detect_components(image_path, coach_dir, train_number, coach_count):\n",
        "    img = cv2.imread(image_path)\n",
        "    if img is None:\n",
        "        print(f\"Error loading image: {image_path}\")\n",
        "        return image_path\n",
        "\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (7, 7), 0)  # Larger kernel for smoother edges\n",
        "    edges = cv2.Canny(blurred, 30, 100)  # Adjusted thresholds for better edge detection\n",
        "\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    annotated_img = img.copy()\n",
        "    for cnt in contours:\n",
        "        area = cv2.contourArea(cnt)\n",
        "        if 3000 < area < 10000:  # Narrower area range for doors\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "            aspect_ratio = w / float(h)\n",
        "            if 0.7 < aspect_ratio < 1.5:  # Tighter aspect ratio for door-like shapes\n",
        "                roi = gray[y:y+h, x:x+w]\n",
        "                avg_intensity = np.mean(roi)\n",
        "                label = \"Door Open\" if avg_intensity < 80 else \"Door Closed\"  # Adjusted threshold\n",
        "\n",
        "                cv2.rectangle(annotated_img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "                cv2.putText(annotated_img, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "    annotated_path = os.path.join(coach_dir, f\"{train_number}_{coach_count}_annotated.jpg\")\n",
        "    cv2.imwrite(annotated_path, annotated_img)\n",
        "    return annotated_path\n",
        "\n",
        "def generate_report(image_paths, output_dir, train_number, coach_count):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(200, 10, txt=f\"Train {train_number} Coverage Report - {coach_count} Coaches\", ln=1, align='C')\n",
        "\n",
        "    for i, img_path in enumerate(image_paths):\n",
        "        pdf.cell(200, 10, txt=f\"Coach {i+1}\", ln=1)\n",
        "        if os.path.exists(img_path):\n",
        "            pdf.image(img_path, x=10, w=180)\n",
        "        else:\n",
        "            pdf.cell(200, 10, txt=f\"Image {img_path} not found\", ln=1)\n",
        "\n",
        "    report_path = os.path.join(output_dir, f\"{train_number}_report.pdf\")\n",
        "    pdf.output(report_path)\n",
        "    print(f\"Report generated at: {report_path}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # For Colab, set video path directly\n",
        "    video_path = \"/content/DHN-side-view-lower-2025-08-31-11-24-27-47.mp4\"\n",
        "    output_dir = \"processed_output\"\n",
        "    main(video_path, output_dir)"
      ]
    }
  ]
}